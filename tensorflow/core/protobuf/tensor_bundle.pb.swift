/*
 * DO NOT EDIT.
 *
 * Generated by the protocol buffer compiler.
 * Source: tensorflow/core/protobuf/tensor_bundle.proto
 *
 */

import Foundation
import SwiftProtobuf


//  Protos used in the tensor bundle module (tf/core/util/tensor_bundle/).

///   Special header that is associated with a bundle.
///  
///   TODO(zongheng,zhifengc): maybe in the future, we can add information about
///   which binary produced this checkpoint, timestamp, etc. Sometime, these can be
///   valuable debugging information. And if needed, these can be used as defensive
///   information ensuring reader (binary version) of the checkpoint and the writer
///   (binary version) must match within certain range, etc.
struct Tensorflow_BundleHeaderProto: ProtobufGeneratedMessage {
  public var swiftClassName: String {return "Tensorflow_BundleHeaderProto"}
  public var protoMessageName: String {return "BundleHeaderProto"}
  public var protoPackageName: String {return "tensorflow"}
  public var jsonFieldNames: [String: Int] {return [
    "numShards": 1,
    "endianness": 2,
    "version": 3,
  ]}
  public var protoFieldNames: [String: Int] {return [
    "num_shards": 1,
    "endianness": 2,
    "version": 3,
  ]}

  private class _StorageClass {
    typealias ProtobufExtendedMessage = Tensorflow_BundleHeaderProto
    var _numShards: Int32 = 0
    var _endianness: Tensorflow_BundleHeaderProto.Endianness = Tensorflow_BundleHeaderProto.Endianness.little
    var _version: Tensorflow_VersionDef? = nil

    init() {}

    func decodeField(setter: inout ProtobufFieldDecoder, protoFieldNumber: Int) throws -> Bool {
      let handled: Bool
      switch protoFieldNumber {
      case 1: handled = try setter.decodeSingularField(fieldType: ProtobufInt32.self, value: &_numShards)
      case 2: handled = try setter.decodeSingularField(fieldType: Tensorflow_BundleHeaderProto.Endianness.self, value: &_endianness)
      case 3: handled = try setter.decodeSingularMessageField(fieldType: Tensorflow_VersionDef.self, value: &_version)
      default:
        handled = false
      }
      return handled
    }

    func traverse(visitor: inout ProtobufVisitor) throws {
      if _numShards != 0 {
        try visitor.visitSingularField(fieldType: ProtobufInt32.self, value: _numShards, protoFieldNumber: 1, protoFieldName: "num_shards", jsonFieldName: "numShards", swiftFieldName: "numShards")
      }
      if _endianness != Tensorflow_BundleHeaderProto.Endianness.little {
        try visitor.visitSingularField(fieldType: Tensorflow_BundleHeaderProto.Endianness.self, value: _endianness, protoFieldNumber: 2, protoFieldName: "endianness", jsonFieldName: "endianness", swiftFieldName: "endianness")
      }
      if let v = _version {
        try visitor.visitSingularMessageField(value: v, protoFieldNumber: 3, protoFieldName: "version", jsonFieldName: "version", swiftFieldName: "version")
      }
    }

    func isEqualTo(other: _StorageClass) -> Bool {
      if _numShards != other._numShards {return false}
      if _endianness != other._endianness {return false}
      if _version != other._version {return false}
      return true
    }

    func copy() -> _StorageClass {
      let clone = _StorageClass()
      clone._numShards = _numShards
      clone._endianness = _endianness
      clone._version = _version
      return clone
    }
  }

  private var _storage = _StorageClass()

  ///   An enum indicating the endianness of the platform that produced this
  ///   bundle.  A bundle can only be read by a platform with matching endianness.
  ///   Defaults to LITTLE, as most modern platforms are little-endian.
  ///  
  ///   Affects the binary tensor data bytes only, not the metadata in protobufs.
  enum Endianness: ProtobufEnum {
    public typealias RawValue = Int
    case little // = 0
    case big // = 1
    case UNRECOGNIZED(Int)

    public init() {
      self = .little
    }

    public init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .little
      case 1: self = .big
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    public init?(name: String) {
      switch name {
      case "little": self = .little
      case "big": self = .big
      default: return nil
      }
    }

    public init?(jsonName: String) {
      switch jsonName {
      case "LITTLE": self = .little
      case "BIG": self = .big
      default: return nil
      }
    }

    public init?(protoName: String) {
      switch protoName {
      case "LITTLE": self = .little
      case "BIG": self = .big
      default: return nil
      }
    }

    public var rawValue: Int {
      get {
        switch self {
        case .little: return 0
        case .big: return 1
        case .UNRECOGNIZED(let i): return i
        }
      }
    }

    public var json: String {
      get {
        switch self {
        case .little: return "\"LITTLE\""
        case .big: return "\"BIG\""
        case .UNRECOGNIZED(let i): return String(i)
        }
      }
    }

    public var hashValue: Int { return rawValue }

    public var debugDescription: String {
      get {
        switch self {
        case .little: return ".little"
        case .big: return ".big"
        case .UNRECOGNIZED(let v): return ".UNRECOGNIZED(\(v))"
        }
      }
    }

  }

  ///   Number of data files in the bundle.
  public var numShards: Int32 {
    get {return _storage._numShards}
    set {_uniqueStorage()._numShards = newValue}
  }

  public var endianness: Tensorflow_BundleHeaderProto.Endianness {
    get {return _storage._endianness}
    set {_uniqueStorage()._endianness = newValue}
  }

  ///   Versioning of the tensor bundle format.
  public var version: Tensorflow_VersionDef {
    get {return _storage._version ?? Tensorflow_VersionDef()}
    set {_uniqueStorage()._version = newValue}
  }
  public var hasVersion: Bool {
    return _storage._version != nil
  }
  public mutating func clearVersion() {
    return _storage._version = nil
  }

  public init() {}

  public mutating func _protoc_generated_decodeField(setter: inout ProtobufFieldDecoder, protoFieldNumber: Int) throws -> Bool {
    return try _uniqueStorage().decodeField(setter: &setter, protoFieldNumber: protoFieldNumber)
  }

  public func _protoc_generated_traverse(visitor: inout ProtobufVisitor) throws {
    try _storage.traverse(visitor: &visitor)
  }

  public func _protoc_generated_isEqualTo(other: Tensorflow_BundleHeaderProto) -> Bool {
    return _storage === other._storage || _storage.isEqualTo(other: other._storage)
  }

  private mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _storage.copy()
    }
    return _storage
  }
}

///   Describes the metadata related to a checkpointed tensor.
struct Tensorflow_BundleEntryProto: ProtobufGeneratedMessage {
  public var swiftClassName: String {return "Tensorflow_BundleEntryProto"}
  public var protoMessageName: String {return "BundleEntryProto"}
  public var protoPackageName: String {return "tensorflow"}
  public var jsonFieldNames: [String: Int] {return [
    "dtype": 1,
    "shape": 2,
    "shardId": 3,
    "offset": 4,
    "size": 5,
    "crc32c": 6,
    "slices": 7,
  ]}
  public var protoFieldNames: [String: Int] {return [
    "dtype": 1,
    "shape": 2,
    "shard_id": 3,
    "offset": 4,
    "size": 5,
    "crc32c": 6,
    "slices": 7,
  ]}

  private class _StorageClass {
    typealias ProtobufExtendedMessage = Tensorflow_BundleEntryProto
    var _dtype: Tensorflow_DataType = Tensorflow_DataType.dtInvalid
    var _shape: Tensorflow_TensorShapeProto? = nil
    var _shardId: Int32 = 0
    var _offset: Int64 = 0
    var _size: Int64 = 0
    var _crc32C: UInt32 = 0
    var _slices: [Tensorflow_TensorSliceProto] = []

    init() {}

    func decodeField(setter: inout ProtobufFieldDecoder, protoFieldNumber: Int) throws -> Bool {
      let handled: Bool
      switch protoFieldNumber {
      case 1: handled = try setter.decodeSingularField(fieldType: Tensorflow_DataType.self, value: &_dtype)
      case 2: handled = try setter.decodeSingularMessageField(fieldType: Tensorflow_TensorShapeProto.self, value: &_shape)
      case 3: handled = try setter.decodeSingularField(fieldType: ProtobufInt32.self, value: &_shardId)
      case 4: handled = try setter.decodeSingularField(fieldType: ProtobufInt64.self, value: &_offset)
      case 5: handled = try setter.decodeSingularField(fieldType: ProtobufInt64.self, value: &_size)
      case 6: handled = try setter.decodeSingularField(fieldType: ProtobufFixed32.self, value: &_crc32C)
      case 7: handled = try setter.decodeRepeatedMessageField(fieldType: Tensorflow_TensorSliceProto.self, value: &_slices)
      default:
        handled = false
      }
      return handled
    }

    func traverse(visitor: inout ProtobufVisitor) throws {
      if _dtype != Tensorflow_DataType.dtInvalid {
        try visitor.visitSingularField(fieldType: Tensorflow_DataType.self, value: _dtype, protoFieldNumber: 1, protoFieldName: "dtype", jsonFieldName: "dtype", swiftFieldName: "dtype")
      }
      if let v = _shape {
        try visitor.visitSingularMessageField(value: v, protoFieldNumber: 2, protoFieldName: "shape", jsonFieldName: "shape", swiftFieldName: "shape")
      }
      if _shardId != 0 {
        try visitor.visitSingularField(fieldType: ProtobufInt32.self, value: _shardId, protoFieldNumber: 3, protoFieldName: "shard_id", jsonFieldName: "shardId", swiftFieldName: "shardId")
      }
      if _offset != 0 {
        try visitor.visitSingularField(fieldType: ProtobufInt64.self, value: _offset, protoFieldNumber: 4, protoFieldName: "offset", jsonFieldName: "offset", swiftFieldName: "offset")
      }
      if _size != 0 {
        try visitor.visitSingularField(fieldType: ProtobufInt64.self, value: _size, protoFieldNumber: 5, protoFieldName: "size", jsonFieldName: "size", swiftFieldName: "size")
      }
      if _crc32C != 0 {
        try visitor.visitSingularField(fieldType: ProtobufFixed32.self, value: _crc32C, protoFieldNumber: 6, protoFieldName: "crc32c", jsonFieldName: "crc32c", swiftFieldName: "crc32C")
      }
      if !_slices.isEmpty {
        try visitor.visitRepeatedMessageField(value: _slices, protoFieldNumber: 7, protoFieldName: "slices", jsonFieldName: "slices", swiftFieldName: "slices")
      }
    }

    func isEqualTo(other: _StorageClass) -> Bool {
      if _dtype != other._dtype {return false}
      if _shape != other._shape {return false}
      if _shardId != other._shardId {return false}
      if _offset != other._offset {return false}
      if _size != other._size {return false}
      if _crc32C != other._crc32C {return false}
      if _slices != other._slices {return false}
      return true
    }

    func copy() -> _StorageClass {
      let clone = _StorageClass()
      clone._dtype = _dtype
      clone._shape = _shape
      clone._shardId = _shardId
      clone._offset = _offset
      clone._size = _size
      clone._crc32C = _crc32C
      clone._slices = _slices
      return clone
    }
  }

  private var _storage = _StorageClass()

  ///   The tensor dtype and shape.
  public var dtype: Tensorflow_DataType {
    get {return _storage._dtype}
    set {_uniqueStorage()._dtype = newValue}
  }

  public var shape: Tensorflow_TensorShapeProto {
    get {return _storage._shape ?? Tensorflow_TensorShapeProto()}
    set {_uniqueStorage()._shape = newValue}
  }
  public var hasShape: Bool {
    return _storage._shape != nil
  }
  public mutating func clearShape() {
    return _storage._shape = nil
  }

  ///   The binary content of the tensor lies in:
  ///     File "shard_id": bytes [offset, offset + size).
  public var shardId: Int32 {
    get {return _storage._shardId}
    set {_uniqueStorage()._shardId = newValue}
  }

  public var offset: Int64 {
    get {return _storage._offset}
    set {_uniqueStorage()._offset = newValue}
  }

  public var size: Int64 {
    get {return _storage._size}
    set {_uniqueStorage()._size = newValue}
  }

  ///   The CRC32C checksum of the tensor bytes.
  public var crc32C: UInt32 {
    get {return _storage._crc32C}
    set {_uniqueStorage()._crc32C = newValue}
  }

  ///   Iff present, this entry represents a partitioned tensor.  The previous
  ///   fields are interpreted as follows:
  ///  
  ///     "dtype", "shape": describe the full tensor.
  ///     "shard_id", "offset", "size", "crc32c": all IGNORED.
  ///        These information for each slice can be looked up in their own
  ///        BundleEntryProto, keyed by each "slice_name".
  public var slices: [Tensorflow_TensorSliceProto] {
    get {return _storage._slices}
    set {_uniqueStorage()._slices = newValue}
  }

  public init() {}

  public mutating func _protoc_generated_decodeField(setter: inout ProtobufFieldDecoder, protoFieldNumber: Int) throws -> Bool {
    return try _uniqueStorage().decodeField(setter: &setter, protoFieldNumber: protoFieldNumber)
  }

  public func _protoc_generated_traverse(visitor: inout ProtobufVisitor) throws {
    try _storage.traverse(visitor: &visitor)
  }

  public func _protoc_generated_isEqualTo(other: Tensorflow_BundleEntryProto) -> Bool {
    return _storage === other._storage || _storage.isEqualTo(other: other._storage)
  }

  private mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _storage.copy()
    }
    return _storage
  }
}
