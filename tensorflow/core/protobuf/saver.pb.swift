/*
 * DO NOT EDIT.
 *
 * Generated by the protocol buffer compiler.
 * Source: tensorflow/core/protobuf/saver.proto
 *
 */

import Foundation
import SwiftProtobuf


///   Protocol buffer representing the configuration of a Saver.
struct Tensorflow_SaverDef: ProtobufGeneratedMessage {
  public var swiftClassName: String {return "Tensorflow_SaverDef"}
  public var protoMessageName: String {return "SaverDef"}
  public var protoPackageName: String {return "tensorflow"}
  public var jsonFieldNames: [String: Int] {return [
    "filenameTensorName": 1,
    "saveTensorName": 2,
    "restoreOpName": 3,
    "maxToKeep": 4,
    "sharded": 5,
    "keepCheckpointEveryNHours": 6,
    "version": 7,
  ]}
  public var protoFieldNames: [String: Int] {return [
    "filename_tensor_name": 1,
    "save_tensor_name": 2,
    "restore_op_name": 3,
    "max_to_keep": 4,
    "sharded": 5,
    "keep_checkpoint_every_n_hours": 6,
    "version": 7,
  ]}

  ///   A version number that identifies a different on-disk checkpoint format.
  ///   Usually, each subclass of BaseSaverBuilder works with a particular
  ///   version/format.  However, it is possible that the same builder may be
  ///   upgraded to support a newer checkpoint format in the future.
  enum CheckpointFormatVersion: ProtobufEnum {
    public typealias RawValue = Int

    ///   Internal legacy format.
    case legacy // = 0

    ///   Current format: tf.Saver() which works with tensorflow::table::Table.
    case v1 // = 1

    ///   Experimental format under development.
    case v2 // = 2
    case UNRECOGNIZED(Int)

    public init() {
      self = .legacy
    }

    public init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .legacy
      case 1: self = .v1
      case 2: self = .v2
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    public init?(name: String) {
      switch name {
      case "legacy": self = .legacy
      case "v1": self = .v1
      case "v2": self = .v2
      default: return nil
      }
    }

    public init?(jsonName: String) {
      switch jsonName {
      case "LEGACY": self = .legacy
      case "V1": self = .v1
      case "V2": self = .v2
      default: return nil
      }
    }

    public init?(protoName: String) {
      switch protoName {
      case "LEGACY": self = .legacy
      case "V1": self = .v1
      case "V2": self = .v2
      default: return nil
      }
    }

    public var rawValue: Int {
      get {
        switch self {
        case .legacy: return 0
        case .v1: return 1
        case .v2: return 2
        case .UNRECOGNIZED(let i): return i
        }
      }
    }

    public var json: String {
      get {
        switch self {
        case .legacy: return "\"LEGACY\""
        case .v1: return "\"V1\""
        case .v2: return "\"V2\""
        case .UNRECOGNIZED(let i): return String(i)
        }
      }
    }

    public var hashValue: Int { return rawValue }

    public var debugDescription: String {
      get {
        switch self {
        case .legacy: return ".legacy"
        case .v1: return ".v1"
        case .v2: return ".v2"
        case .UNRECOGNIZED(let v): return ".UNRECOGNIZED(\(v))"
        }
      }
    }

  }

  ///   The name of the tensor in which to specify the filename when saving or
  ///   restoring a model checkpoint.
  public var filenameTensorName: String = ""

  ///   The operation to run when saving a model checkpoint.
  public var saveTensorName: String = ""

  ///   The operation to run when restoring a model checkpoint.
  public var restoreOpName: String = ""

  ///   Maximum number of checkpoints to keep.  If 0, no checkpoints are deleted.
  public var maxToKeep: Int32 = 0

  ///   Shard the save files, one per device that has Variable nodes.
  public var sharded: Bool = false

  ///   How often to keep an additional checkpoint. If not specified, only the last
  ///   "max_to_keep" checkpoints are kept; if specified, in addition to keeping
  ///   the last "max_to_keep" checkpoints, an additional checkpoint will be kept
  ///   for every n hours of training.
  public var keepCheckpointEveryNHours: Float = 0

  public var version: Tensorflow_SaverDef.CheckpointFormatVersion = Tensorflow_SaverDef.CheckpointFormatVersion.legacy

  public init() {}

  public mutating func _protoc_generated_decodeField(setter: inout ProtobufFieldDecoder, protoFieldNumber: Int) throws -> Bool {
    let handled: Bool
    switch protoFieldNumber {
    case 1: handled = try setter.decodeSingularField(fieldType: ProtobufString.self, value: &filenameTensorName)
    case 2: handled = try setter.decodeSingularField(fieldType: ProtobufString.self, value: &saveTensorName)
    case 3: handled = try setter.decodeSingularField(fieldType: ProtobufString.self, value: &restoreOpName)
    case 4: handled = try setter.decodeSingularField(fieldType: ProtobufInt32.self, value: &maxToKeep)
    case 5: handled = try setter.decodeSingularField(fieldType: ProtobufBool.self, value: &sharded)
    case 6: handled = try setter.decodeSingularField(fieldType: ProtobufFloat.self, value: &keepCheckpointEveryNHours)
    case 7: handled = try setter.decodeSingularField(fieldType: Tensorflow_SaverDef.CheckpointFormatVersion.self, value: &version)
    default:
      handled = false
    }
    return handled
  }

  public func _protoc_generated_traverse(visitor: inout ProtobufVisitor) throws {
    if filenameTensorName != "" {
      try visitor.visitSingularField(fieldType: ProtobufString.self, value: filenameTensorName, protoFieldNumber: 1, protoFieldName: "filename_tensor_name", jsonFieldName: "filenameTensorName", swiftFieldName: "filenameTensorName")
    }
    if saveTensorName != "" {
      try visitor.visitSingularField(fieldType: ProtobufString.self, value: saveTensorName, protoFieldNumber: 2, protoFieldName: "save_tensor_name", jsonFieldName: "saveTensorName", swiftFieldName: "saveTensorName")
    }
    if restoreOpName != "" {
      try visitor.visitSingularField(fieldType: ProtobufString.self, value: restoreOpName, protoFieldNumber: 3, protoFieldName: "restore_op_name", jsonFieldName: "restoreOpName", swiftFieldName: "restoreOpName")
    }
    if maxToKeep != 0 {
      try visitor.visitSingularField(fieldType: ProtobufInt32.self, value: maxToKeep, protoFieldNumber: 4, protoFieldName: "max_to_keep", jsonFieldName: "maxToKeep", swiftFieldName: "maxToKeep")
    }
    if sharded != false {
      try visitor.visitSingularField(fieldType: ProtobufBool.self, value: sharded, protoFieldNumber: 5, protoFieldName: "sharded", jsonFieldName: "sharded", swiftFieldName: "sharded")
    }
    if keepCheckpointEveryNHours != 0 {
      try visitor.visitSingularField(fieldType: ProtobufFloat.self, value: keepCheckpointEveryNHours, protoFieldNumber: 6, protoFieldName: "keep_checkpoint_every_n_hours", jsonFieldName: "keepCheckpointEveryNHours", swiftFieldName: "keepCheckpointEveryNHours")
    }
    if version != Tensorflow_SaverDef.CheckpointFormatVersion.legacy {
      try visitor.visitSingularField(fieldType: Tensorflow_SaverDef.CheckpointFormatVersion.self, value: version, protoFieldNumber: 7, protoFieldName: "version", jsonFieldName: "version", swiftFieldName: "version")
    }
  }

  public func _protoc_generated_isEqualTo(other: Tensorflow_SaverDef) -> Bool {
    if filenameTensorName != other.filenameTensorName {return false}
    if saveTensorName != other.saveTensorName {return false}
    if restoreOpName != other.restoreOpName {return false}
    if maxToKeep != other.maxToKeep {return false}
    if sharded != other.sharded {return false}
    if keepCheckpointEveryNHours != other.keepCheckpointEveryNHours {return false}
    if version != other.version {return false}
    return true
  }
}
